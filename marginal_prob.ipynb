{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90cf82e5-4fdb-4133-9b30-4def9596749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningEmpty\n",
      "[tensor(-5.5477), tensor(-3.0003), tensor(-3.0134), tensor(-4.0511)]\n",
      "[tensor(-5.6259), tensor(-3.0719), tensor(-3.0888), tensor(-4.1120)]\n",
      "[tensor(-5.2717), tensor(-2.6832), tensor(-2.6922), tensor(-3.7161)]\n",
      "[tensor(-5.5276), tensor(-2.8979), tensor(-2.9253), tensor(-3.9666)]\n",
      "[tensor(-5.3546), tensor(-2.7303), tensor(-2.7446), tensor(-3.7522)]\n",
      "[tensor(-5.5138), tensor(-2.9950), tensor(-3.0019), tensor(-4.0470)]\n",
      "./outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningError\n",
      "[tensor(-4.3410), tensor(-4.1077), tensor(-7.8504), tensor(-3.0475)]\n",
      "[tensor(-4.1401), tensor(-3.9294), tensor(-7.7465), tensor(-2.8620)]\n",
      "[tensor(-4.0389), tensor(-3.8317), tensor(-7.6233), tensor(-2.7040)]\n",
      "[tensor(-4.0657), tensor(-3.9038), tensor(-7.5422), tensor(-2.7624)]\n",
      "[tensor(-4.2351), tensor(-4.0185), tensor(-7.6680), tensor(-2.9239)]\n",
      "[tensor(-4.0818), tensor(-3.8854), tensor(-7.6906), tensor(-2.7465)]\n",
      "./outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningNULL\n",
      "[tensor(-3.5609), tensor(-1.8321), tensor(-1.7667), tensor(-1.9709)]\n",
      "[tensor(-3.3904), tensor(-1.7224), tensor(-1.7958), tensor(-2.0013)]\n",
      "[tensor(-3.3547), tensor(-1.5454), tensor(-1.4641), tensor(-1.6647)]\n",
      "[tensor(-3.3650), tensor(-1.6302), tensor(-1.6505), tensor(-1.8628)]\n",
      "[tensor(-3.4809), tensor(-1.7589), tensor(-1.4629), tensor(-1.6771)]\n",
      "[tensor(-3.3623), tensor(-1.5741), tensor(-1.7164), tensor(-1.9182)]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "\n",
    "components_list = [\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningEmpty',\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningError',\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningNULL'\n",
    "]\n",
    "prob_postfix_list = [\n",
    "    '_joint0sh_beams_log_prob.pkl',\n",
    "    '_joint1sh1_beams_log_prob.pkl',\n",
    "    '_joint1sh2_beams_log_prob.pkl',\n",
    "    '_joint1sh3_beams_log_prob.pkl',\n",
    "    '_joint1sh4_beams_log_prob.pkl',\n",
    "    '_joint1sh5_beams_log_prob.pkl'\n",
    "]\n",
    "output_postfix = '_joint6comp_beams_log_prob.pkl'\n",
    "\n",
    "for comp_candidates in components_list:\n",
    "    print(comp_candidates)\n",
    "    log_sum = None\n",
    "    for postfix in prob_postfix_list:\n",
    "        filename= comp_candidates + postfix\n",
    "        with open(filename , 'rb' ) as f:\n",
    "            prob_list = pkl.load(f)\n",
    "            # prob_list = torch.load(f, map_location=torch.device('cpu'), weights_only=False)\n",
    "        print( prob_list[0:4] )\n",
    "        prob_tensor = torch.stack(prob_list)\n",
    "        if log_sum is None:\n",
    "            log_sum = prob_tensor\n",
    "        else:\n",
    "            # print(f'selection_score_with_other_response:{selection_score_with_other_response} --> {selection_score_with_other_response.dtype}')\n",
    "            # print(f'selection_score:{selection_score} --> {selection_score.dtype}')\n",
    "            alpha = torch.maximum( prob_tensor , log_sum )\n",
    "            beta = torch.minimum( prob_tensor , log_sum )\n",
    "            log_sum = alpha + torch.log1p(torch.exp(beta-alpha))\n",
    "    log_sum_list = log_sum.tolist()\n",
    "    with open(comp_candidates+output_postfix , 'wb') as f:\n",
    "        pkl.dump(log_sum_list, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cbe1b4e-6ec9-42b6-b7f2-cadf07881c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "num_beam = 16 # We should not forget to set this parameter correctly!!\n",
    "new_candid_prob_list = []\n",
    "new_output_prefix = '_a1b1Joint6comp_beams_log_prob.pkl'\n",
    "for beam_index in range(0,1534*num_beam,num_beam):\n",
    "    candid_prob_list = []\n",
    "    for idx , comp_candidates in enumerate(components_list):\n",
    "        \n",
    "        if idx <= len(new_candid_prob_list):\n",
    "            new_candid_prob_list.append([])\n",
    "            \n",
    "        filename= comp_candidates + output_postfix\n",
    "        with open(filename , 'rb' ) as f:\n",
    "            prob_list = pkl.load(f)\n",
    "        candid_prob_list.extend(prob_list[beam_index:beam_index+num_beam])\n",
    "        \n",
    "    candid_prob_list_min = min(candid_prob_list)\n",
    "    candid_prob_list_max = max(candid_prob_list)\n",
    "    candid_prob_list_scaled = [(x - candid_prob_list_min) / (candid_prob_list_max - candid_prob_list_min) for x in candid_prob_list]\n",
    "    \n",
    "    # Step 2: Apply exponentiation to amplify differences\n",
    "    # alpha = 1  # You can experiment with different values #It kinda give the original value\n",
    "    # beta = .087 #It kinda give the original value\n",
    "    # gama = 0.275 #It kinda give the original value\n",
    "    alpha = 1  \n",
    "    beta = 1 \n",
    "    gama = 0 \n",
    "    p_transformed = [beta * x ** alpha + gama for x in candid_prob_list_scaled]\n",
    "    for i in range(0, len(p_transformed), num_beam):\n",
    "        new_candid_prob_list[ math.ceil(i/num_beam) ].extend(p_transformed[i:i+num_beam])\n",
    "\n",
    "for prob_list, comp_candidates in zip(new_candid_prob_list, components_list):\n",
    "    with open( comp_candidates + new_output_prefix , 'wb') as f:\n",
    "        pkl.dump(prob_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d877b67-2abb-49d3-a380-af3c1a5984e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results in:\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_0shot_SFTCodeS-15b_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_0shot_SFTCodeS-15b_refinedNull_joint6comp_beams_log_prob.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_1Of0-5shot_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_1Of0-5shot_refinedNull_joint6comp_beams_log_prob.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_2Of0-5shot_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_2Of0-5shot_refinedNull_joint6comp_beams_log_prob.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_3Of0-5shot_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_3Of0-5shot_refinedNull_joint6comp_beams_log_prob.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_4Of0-5shot_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_4Of0-5shot_refinedNull_joint6comp_beams_log_prob.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_5Of0-5shot_refinedNull.pkl\n",
      "./outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_5Of0-5shot_refinedNull_joint6comp_beams_log_prob.pkl\n"
     ]
    }
   ],
   "source": [
    "#The code to put the refined queries back into their place\n",
    "num_beam = 16 # We should not forget to set this parameter correctly!!\n",
    "refined_candidates_files = [\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningEmpty.pkl',\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningError.pkl',\n",
    "    './outputs/raw/output_01shot_6in00-5shotComps_16samples_SFTCodeS-15b_RefiningNULL.pkl'\n",
    "]\n",
    "original_components = [\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_0shot_SFTCodeS-15b.pkl',\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_1Of0-5shot.pkl',\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_2Of0-5shot.pkl',\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_3Of0-5shot.pkl',\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_4Of0-5shot.pkl',\n",
    "    './outputs/raw/output_CodeS_candid16_bird_wEvidence_1shot_SFTCodeS-15b_5Of0-5shot.pkl'\n",
    "]\n",
    "probability_postfix = '_joint6comp_beams_log_prob.pkl'\n",
    "\n",
    "new_components_postfix = '_refinedNull'\n",
    "\n",
    "old_candids = []\n",
    "old_probs = []\n",
    "#Loading all the files in lists\n",
    "for orig_comp in original_components:\n",
    "    with open(orig_comp , 'rb') as f:\n",
    "        old_candids.append(pkl.load(f))\n",
    "    with open( orig_comp[:-4] + probability_postfix , 'rb') as f:\n",
    "        old_probs.append(pkl.load(f))\n",
    "        \n",
    "refined_candid_file = refined_candidates_files[ 2 ]\n",
    "with open( refined_candid_file , 'rb') as f:\n",
    "    refined_candids = pkl.load(f)\n",
    "with open( refined_candid_file[:-4]+probability_postfix , 'rb' ) as f:\n",
    "    refined_probs = pkl.load(f)\n",
    "\n",
    "\n",
    "last_prob_idx = 0\n",
    "for idx , refine_dict in enumerate(refined_candids):\n",
    "    for key in refine_dict.keys():\n",
    "        start_in_orig_comps = idx*num_beam\n",
    "        for comp_idx , comp_old_candids in enumerate(old_candids):\n",
    "            for beam_idx , candid in enumerate(comp_old_candids[ start_in_orig_comps : start_in_orig_comps + num_beam ]):\n",
    "                if key == candid:\n",
    "                    old_candids[comp_idx][start_in_orig_comps + beam_idx] = refine_dict[key]\n",
    "                    old_probs[comp_idx][start_in_orig_comps + beam_idx] = refined_probs[last_prob_idx]\n",
    "        last_prob_idx += 1\n",
    "\n",
    "print('Saving the results in:')\n",
    "components_list = []\n",
    "output_postfix = probability_postfix #so that we can scale the probabilities in the above cell\n",
    "for idx , (candids , probs) in enumerate(zip(old_candids,old_probs)):\n",
    "    comp_candid_filename = original_components[idx][:-4] + new_components_postfix + '.pkl'\n",
    "    comp_prob_filename = original_components[idx][:-4] + new_components_postfix + probability_postfix\n",
    "    with open(comp_candid_filename , 'wb') as f:\n",
    "        pkl.dump(candids , f)\n",
    "        print(comp_candid_filename)\n",
    "        components_list.append(comp_candid_filename[:-4]) #so that we can scale the probabilities in the above cell\n",
    "    with open(comp_prob_filename , 'wb') as f:\n",
    "        pkl.dump(probs , f)\n",
    "        print(comp_prob_filename)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
