{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e271cbbe-e42d-4e30-8cbc-75a0442fb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open('./DAIL-SQL/dataset/process/SPIDER-TEST_SQL_0-SHOT_CTX-200_ANS-2048/questions.json' , 'r') as f:\n",
    "#     generated_prompts_file_byte = f.read()\n",
    "#     generated_prompts = json.loads(generated_prompts_file_byte)\n",
    "\n",
    "with open('./codeS_pred/ENSEMBLE_seqLevelVote_SQLscore_BIRD-TEST_SQL_1_3_5-SHOT_EUCDISQUESTIONMASK_QA-EXAMPLE_CTX-200_ANS-2048_codeS_1b.json' , 'r') as f:\n",
    "    generated_response_file_byte = f.read()\n",
    "    generated_response = json.loads(generated_response_file_byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc89654e-3f05-4532-a0d2-cf86cd8ac075",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./llama_pred/BIRD-TEST_SQL_0-SHOT_CTX-200_ANS-2048_evidence_Llama_7b.txt' , 'w')as f:\n",
    "    for i in generated_response['questions']:\n",
    "        f.write( i['response']+'\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ece1eda-d0e4-47b9-bd09-dd00834ed478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prompt_tokens', 'prompt', 'response', 'n_examples', 'db_id'])\n"
     ]
    }
   ],
   "source": [
    "#Code to make the dataset (DAIL style dataset) from CodeS predictions and the generated prompts\n",
    "with open('./llama_pred/BIRD-TEST_SQL_5-SHOT_EUCDISMASKPRESKLSIMTHR_QA-EXAMPLE_CTX-200_ANS-2048_Llama_7b.json' , 'r') as f:\n",
    "    file_bytes = f.read()\n",
    "    reference_json = json.loads(file_bytes)\n",
    "\n",
    "print(reference_json['questions'][0].keys())\n",
    "\n",
    "\n",
    "with open('./codeS_pred/pred_codes-1b_BIRD_table_num_5_column_num_6_5-shot_max_tokens_8192_max_new_tokens_256.json' , 'r') as f:\n",
    "    file_bytes = f.read()\n",
    "    pred_json = json.loads(file_bytes)\n",
    "i = 0\n",
    "\n",
    "with open('./codeS_pred/prompts_codes-1b_BIRD_table_num_5_column_num_6_5-shot_max_tokens_8192_max_new_tokens_256.json' , 'r') as f:\n",
    "    file_bytes = f.read()\n",
    "    prompts_json = json.loads(file_bytes)\n",
    "\n",
    "for i in pred_json.keys():\n",
    "    response = pred_json[i]\n",
    "    prompts = prompts_json[i]\n",
    "    reference_json['questions'][int(i)]['prompt'] = prompts\n",
    "    reference_json['questions'][int(i)]['response'] = response.split('----- bird -----')[0]\n",
    "\n",
    "with open('./codeS_pred/codes-1b_BIRD_table_num_5_column_num_6_5-shot_max_tokens_8192_max_new_tokens_256.json' , 'w' )as f:\n",
    "    json.dump(reference_json , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "899ffe40-d041-4327-92b3-efd14c9409b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('output_sequences-1.pkl', 'rb') as f:  # open a text file\n",
    "    output_sequences = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f60b7b7-62e4-4293-8cae-ece743cdd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "def extract_prompt_from_list_of_questions(question_list):\n",
    "    batch_list = []\n",
    "    for i in question_list:\n",
    "        batch_list.append(i['prompt'])\n",
    "    return batch_list\n",
    "\n",
    "from utils.post_process import get_exec_output\n",
    "\n",
    "import psutil\n",
    "def query_to_db(query , db_id , db_dir ):\n",
    "    db_path = f\"{db_dir}/{db_id}/{db_id}\"\n",
    "    flag, denotation = get_exec_output(\n",
    "            db_path,\n",
    "            query)\n",
    "    \n",
    "    return flag, denotation\n",
    "\n",
    "from threading import Thread\n",
    "import threading\n",
    "import ctypes\n",
    "class Thread_with_exception(Thread):\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                 args=(), kwargs={}, Verbose=None , daemon=False):\n",
    "        Thread.__init__(self, group, target, name, args, kwargs , daemon=daemon)\n",
    "        \n",
    "        self._return = None\n",
    "            \n",
    "    def run(self):\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args,\n",
    "                                                **self._kwargs)\n",
    "         \n",
    "    def get_id(self):\n",
    "        # returns id of the respective thread\n",
    "        if hasattr(self, '_thread_id'):\n",
    "            return self._thread_id\n",
    "        for id, thread in threading._active.items():\n",
    "            if thread is self:\n",
    "                return id\n",
    "\n",
    "    def join(self, *args):\n",
    "        Thread.join(self, *args)\n",
    "        return self._return\n",
    " \n",
    "    def raise_exception(self):\n",
    "        thread_id = self.get_id()\n",
    "        res = ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, ctypes.py_object(SystemExit))\n",
    "        if res > 1:\n",
    "            ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, 0)\n",
    "            print('Exception raise failure')\n",
    "            \n",
    "\n",
    "import time\n",
    "from utils.post_process import result_eq\n",
    "\n",
    "def is_queries_equal(testing_query , ground_truth_query , db_id , db_dir, timeout_time , gt_results = None):\n",
    "    #Input:\n",
    "        #time_out_time: integer: time in seconds\n",
    "    \n",
    "    if ground_truth_query!='':\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            f.write(f\"procceing the ground_truth_query:\\n{ground_truth_query}\\n\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        gt_flag, gt_denotation = query_to_db(ground_truth_query , db_id , db_dir)\n",
    "    \n",
    "        gt_process_time = time.time() - start_time\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            f.write(f\"processing time: {gt_process_time}\\n\\n\")\n",
    "        gt_results = (gt_flag, gt_denotation , gt_process_time)\n",
    "        \n",
    "    else:\n",
    "        gt_flag, gt_denotation, gt_process_time = gt_results\n",
    "\n",
    "    max_timeout_time = max( timeout_time , 2*gt_process_time )\n",
    "\n",
    "    test_thread = Thread_with_exception(target= query_to_db , args = (testing_query , db_id , db_dir ) , daemon=True )\n",
    "    with open('./log.txt', 'a') as f:\n",
    "        f.write(f\"proccessing the testing_query:\\n{testing_query}\\n\")\n",
    "    start_time = time.time()\n",
    "    test_thread.start()\n",
    "    test_result = test_thread.join(max_timeout_time)\n",
    "    if test_thread.is_alive():\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            f.write(f\"**********processing is terminated due to timeout. max_timeout_time: {max_timeout_time}\\n\")\n",
    "        test_thread.raise_exception()\n",
    "        test_thread.join()\n",
    "        return False, gt_results\n",
    "        \n",
    "    test_flag, test_denotation = test_result\n",
    "    with open('./log.txt', 'a') as f:\n",
    "        f.write(f\"Processing time for the testing query: {time.time() - start_time}\\n\\n\")\n",
    "    \n",
    "    if gt_flag[0] != 'result':\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            f.write(f\"!!!!!!!!!!The following ground truth has an error:\\n{ground_truth_query}\\n\\n\")\n",
    "        return False, gt_results\n",
    "    elif test_flag[0] != 'result':\n",
    "        return False, gt_results\n",
    "    elif 'ORDER BY' in ground_truth_query or 'order by' in ground_truth_query:\n",
    "        is_equal = result_eq(gt_flag[1] , test_flag[1] , order_matters=True)\n",
    "    else:\n",
    "        is_equal = result_eq(gt_flag[1] , test_flag[1] , order_matters=False)\n",
    "    \n",
    "    return is_equal, gt_results\n",
    "    \n",
    "import os\n",
    "def put_responses_back_to_json_dataset(index , json_dataset , sequences, dataset_type='spider' , timeout_time=60):#dataset_type=spider/bird\n",
    "    #Inputs:\n",
    "        #sequences: List of [ { 'generated_text' : gen_text } ] or [gen_text1 , gen_text2 , ...]\n",
    "        #json_dataset: json dataset that contains the ground truth in its 'response' part\n",
    "            #If the elements in input sequences are like seq[0]['generated_text'] then json_dataset should contain the prompt in 'prompts' part\n",
    "    gt_result_cache_file = './cache/' + dataset_type + '_results.pkl'\n",
    "    gt_results_is_cached = False\n",
    "    gt_results_list = []\n",
    "    \n",
    "    if os.path.isfile(gt_result_cache_file):\n",
    "        gt_results_is_cached = True\n",
    "        with open(gt_result_cache_file , 'rb' )as f:\n",
    "            gt_results_list = pkl.load(f)\n",
    "    \n",
    "    db_dir = './DAIL-SQL/dataset/'+ dataset_type +'/database'\n",
    "    execution_accuracy = 0\n",
    "    \n",
    "    for i in range( 0, len(sequences), 1 ):\n",
    "        seq = sequences[i]\n",
    "        # print(f\"Number of processed sequences: {i}\\t|\\tNumber of correct queries: {execution_accuracy} \\n\")\n",
    "        # if i%10==0:\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            f.write(f\"Number of processed sequences: {i}\\t|\\tNumber of correct queries: {execution_accuracy} \\n\")\n",
    "            \n",
    "        prompt_len = len ( json_dataset['questions'][index+i]['prompt'] )\n",
    "        if isinstance(seq, list):\n",
    "            gen_text = seq[0]['generated_text'][prompt_len:]\n",
    "        else:\n",
    "            # gen_text = seq[prompt_len:]\n",
    "            gen_text = seq\n",
    "            \n",
    "        processed_gen_text = post_process_get_sql_from_gentext(gen_text)\n",
    "        \n",
    "        db_id = json_dataset['questions'][index+i]['db_id']\n",
    "\n",
    "        if gt_results_is_cached:\n",
    "            is_equal , gt_results = is_queries_equal(processed_gen_text , '' , db_id , db_dir, timeout_time , gt_results = gt_results_list[i])\n",
    "        else:\n",
    "            ground_truth = post_process_get_sql_from_gentext( json_dataset['questions'][index+i]['response'] )\n",
    "            is_equal , gt_results = is_queries_equal(processed_gen_text , ground_truth , db_id , db_dir, timeout_time )\n",
    "            gt_results_list.append(gt_results)\n",
    "        \n",
    "        json_dataset['questions'][index+i]['response'] = processed_gen_text\n",
    "        execution_accuracy += is_equal\n",
    "        # print('is_equal: ', is_equal)\n",
    "        # print('--------------------------')\n",
    "    if not gt_results_is_cached:\n",
    "        with open(gt_result_cache_file , 'wb' )as f:\n",
    "            pkl.dump( gt_results_list , f )\n",
    "        \n",
    "    return execution_accuracy\n",
    "\n",
    "from utils.post_process import process_duplication\n",
    "def post_process_get_sql_from_gentext(gen_text):\n",
    "    # remove \\n and extra spaces\n",
    "    sql = \" \".join(gen_text.replace(\"\\n\", \" \").split())\n",
    "    sql = process_duplication(sql)\n",
    "    # python version should >= 3.8\n",
    "    if sql.startswith(\"SELECT\"):\n",
    "        sql = sql\n",
    "    elif sql.startswith(\" \"):\n",
    "        sql = \"SELECT\" + sql\n",
    "    else:\n",
    "        sql = \"SELECT \" + sql\n",
    "    return sql\n",
    "\n",
    "data_size=1034\n",
    "def eval_list_sql(sql_list , groundtruth_json_file_name , output_filename='' , dataset_type='spider' ):\n",
    "    #This function gets a list of sql predictions and evalueates it and creates a dail style dataset if the output_file_name is given\n",
    "    # groundtruth_json_file_name: Address of a dail style dataset containing the groundtruth in its response part.\n",
    "        #If the sql_list elements are of shape seq[0]['generated_text'] groundtruth_json_file_name should have the prompts too\n",
    "    with open(groundtruth_json_file_name , 'r') as f:\n",
    "        generated_prompts_file_byte = f.read()\n",
    "        generated_prompts = json.loads(generated_prompts_file_byte)\n",
    "        exec_acc = put_responses_back_to_json_dataset( 0 , generated_prompts , sql_list , dataset_type=dataset_type )\n",
    "    print('execution accuracy = ' , exec_acc/data_size)\n",
    "    with open('./log.txt', 'a') as f:\n",
    "        f.write(f\"execution accuracy = {exec_acc/data_size} \\n\")\n",
    "    if output_filename !='':\n",
    "        with open( output_filename , 'w' )as f:\n",
    "            json.dump(generated_prompts , f)\n",
    "\n",
    "def dail_dataset_to_response_list( dail_style_dataset_name ):\n",
    "    #This function gets a dail-style dataset and returns the all the responses in that dataset in a list.\n",
    "    return_list = []\n",
    "    with open( dail_style_dataset_name , 'r') as f:\n",
    "        generated_response_file_byte = f.read()\n",
    "        generated_response = json.loads(generated_response_file_byte)\n",
    "    for i in generated_response['questions']:\n",
    "        return_list.append( i['response'] )\n",
    "    return return_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0946f24a-1343-4624-87f9-5036fc122d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution accuracy =  0.30077369439071566\n"
     ]
    }
   ],
   "source": [
    "#re-evaluating a dataset that is created before\n",
    "import json\n",
    "groundtruth_json_file_name = './DAIL-SQL/dataset/process/SPIDER-TEST_SQL_0-SHOT_CTX-200_ANS-2048/questions.json'\n",
    "\n",
    "evaluating_dataset = './llama_pred/SPIDER_beam_4_generate-TEST_SQL_3-SHOT_EUCDISMASKPRESKLSIMTHR_QA-EXAMPLE_CTX-200_ANS-2048_llama_7b.json'\n",
    "\n",
    "output_sequences = dail_dataset_to_response_list( evaluating_dataset )\n",
    "\n",
    "eval_list_sql(output_sequences , groundtruth_json_file_name , output_filename='' , dataset_type='spider' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fc11f3d-c76f-4707-bfb8-e72beb0eb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution accuracy =  0.3578336557059961\n"
     ]
    }
   ],
   "source": [
    "#evaluating some generated prompts recently generated.\n",
    "import pickle as pkl\n",
    "\n",
    "groundtruth_json_file_name = './DAIL-SQL/dataset/process/SPIDER-TEST_SQL_3-SHOT_EUCDISMASKPRESKLSIMTHR_QA-EXAMPLE_CTX-200_ANS-2048_llama_7b/questions.json'\n",
    "\n",
    "# with open('./output_sequences-5_lenpen1.pkl', 'rb') as f:  # open a text file\n",
    "#     output_sequences = pkl.load(f)\n",
    "\n",
    "eval_list_sql(output_sequences , groundtruth_json_file_name , \n",
    "              output_filename='./llama_pred/SPIDER_beam_4_lenpen0-TEST_SQL_3-SHOT_9-12_EUCDISMASKPRESKLSIMTHR_QA-EXAMPLE_CTX-200_ANS-2048_llama_7b.json' , dataset_type='spider' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f736283f-f1ab-4f2d-9873-c740c6b1a656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs2/output_sequences_0_50-4.pkl\n",
      "./outputs2/output_sequences_50_100-4.pkl\n",
      "./outputs2/output_sequences_100_150-4.pkl\n",
      "./outputs2/output_sequences_150_200-4.pkl\n",
      "./outputs2/output_sequences_200_250-4.pkl\n",
      "./outputs2/output_sequences_250_300-4.pkl\n",
      "./outputs2/output_sequences_300_350-4.pkl\n",
      "./outputs2/output_sequences_350_400-4.pkl\n",
      "./outputs2/output_sequences_400_450-4.pkl\n",
      "./outputs2/output_sequences_450_500-4.pkl\n",
      "./outputs2/output_sequences_500_550-4.pkl\n",
      "./outputs2/output_sequences_550_600-4.pkl\n",
      "./outputs2/output_sequences_600_650-4.pkl\n",
      "./outputs2/output_sequences_650_700-4.pkl\n",
      "./outputs2/output_sequences_700_750-4.pkl\n",
      "./outputs2/output_sequences_750_800-4.pkl\n",
      "./outputs2/output_sequences_800_850-4.pkl\n",
      "./outputs2/output_sequences_850_900-4.pkl\n",
      "./outputs2/output_sequences_900_950-4.pkl\n",
      "./outputs2/output_sequences_950_1000-4.pkl\n",
      "./outputs2/output_sequences_1000_end-4.pkl\n",
      "1034\n"
     ]
    }
   ],
   "source": [
    "#grouping the pieces of output_sequences\n",
    "import pickle as pkl\n",
    "prefix = './outputs2/output_sequences_'\n",
    "output_sequences = []\n",
    "for i in range(0 , 1050 , 50):\n",
    "    if i <1000:\n",
    "        if i == 0: \n",
    "            file_name = prefix + '0_'  + str(i+50).lstrip('0') + '-4.pkl'\n",
    "        else:\n",
    "            file_name = prefix + str(i).lstrip('0') + '_' + str(i+50).lstrip('0') + '-4.pkl'\n",
    "    else:\n",
    "        file_name = prefix + str(i).lstrip('0') + '_end' + '-4.pkl'\n",
    "    print(file_name)\n",
    "    with open(file_name , 'rb') as f:\n",
    "        part_of_output = pkl.load(f)\n",
    "    output_sequences.extend(part_of_output)\n",
    "\n",
    "print( len(output_sequences) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54c529b8-170b-4de2-96ae-9b99e29c8211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(*) FROM Country AS T1 JOIN CountryLanguage AS T2 ON T1.id  =  T2.country_id WHERE T2.language  =  \"Chinese\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_sequences[751])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7b2326c-2969-463e-89bd-a02b82e76096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(DISTINCT PetType) FROM Has_Pet\\n\\n', 'count(DISTINCT PetType) FROM Has_Pet\\n\\n\n",
      "count(DISTINCT PetType) FROM Has_Pet\n",
      "\n",
      "', 'count(DISTINCT PetType) FROM Has_Pet\n",
      "\n",
      "\n",
      "PetType, MAX(weight) FROM Pets GROUP BY PetType\\n\\n', 'count(*) FROM Has_Pet WHERE StuID > 20\\n\\n\n",
      "PetType, MAX(weight) FROM Pets GROUP BY PetType\n",
      "\n",
      "', 'count(*) FROM Has_Pet WHERE StuID > 20\n",
      "\n",
      "\n",
      "StuID, weight FROM Has_Pet WHERE PetID >  1\\n\\n', 'avg(pet_age) ,  max(pet_age) FROM Has_Pet\\n\\n\n",
      "StuID, weight FROM Has_Pet WHERE PetID >  1\n",
      "\n",
      "', 'avg(pet_age) ,  max(pet_age) FROM Has_Pet\n",
      "\n",
      "\n",
      "avg(age) FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet)\\n\\n', 'avg(age) FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet)\\n\\n\n",
      "avg(age) FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet)\n",
      "\n",
      "', 'avg(age) FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet)\n",
      "\n",
      "\n",
      "count(*) FROM continents\\n\\n', 'count(*) FROM continents\\n\\n\n",
      "count(*) FROM continents\n",
      "\n",
      "', 'count(*) FROM continents\n",
      "\n",
      "\n",
      "ContId, Continent, COUNT(*) FROM continents GROUP BY ContId, Continent\\n\\n', 'count(*) FROM countries\\n\\n\n",
      "ContId, Continent, COUNT(*) FROM continents GROUP BY ContId, Continent\n",
      "\n",
      "', 'count(*) FROM countries\n",
      "\n",
      "\n",
      "StuID, Fname, Age FROM Student JOIN Has_Pet ON StuID = PetID\\n\\n', 'DISTINCT StuID, Fname, Age FROM Student\\nJOIN Has_Pet ON StuID = Has_Pet.StuID\\nWHERE PetID IS NOT NULL\\n\\n\n",
      "StuID, Fname, Age FROM Student JOIN Has_Pet ON StuID = PetID\n",
      "\n",
      "', 'DISTINCT StuID, Fname, Age FROM Student\n",
      "JOIN Has_Pet ON StuID = Has_Pet.StuID\n",
      "WHERE PetID IS NOT NULL\n",
      "\n",
      "\n",
      "StuID, Fname, Age FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\\n\\n', 'StuID, LName, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\\n\\n\n",
      "StuID, Fname, Age FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\n",
      "\n",
      "', 'StuID, LName, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\n",
      "\n",
      "\n",
      "avg(pet_age) ,  max(pet_age) FROM Pets GROUP BY pet_type\\n\\n', 'avg(weight) FROM Pets\\n\\n\n",
      "avg(pet_age) ,  max(pet_age) FROM Pets GROUP BY pet_type\n",
      "\n",
      "', 'avg(weight) FROM Pets\n",
      "\n",
      "\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\\n\\n', \"StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND PetType = 'Cat' OR PetType = 'Dog'\\n\\n\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\n",
      "\n",
      "', \"StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND PetType = 'Cat' OR PetType = 'Dog'\n",
      "\n",
      "\n",
      "StuID, count(PetID) FROM Has_Pet GROUP BY StuID\\n\\n', 'StuID, LName, Fname, Sex, PetID, PetType, pet_age, weight FROM Student\\nJOIN Has_Pet ON StuID = PetID\\nGROUP BY StuID, LName, Fname, Sex, PetID, PetType, pet_age, weight\\nHAVING count(PetID) > 1\\n\\n\n",
      "StuID, count(PetID) FROM Has_Pet GROUP BY StuID\n",
      "\n",
      "', 'StuID, LName, Fname, Sex, PetID, PetType, pet_age, weight FROM Student\n",
      "JOIN Has_Pet ON StuID = PetID\n",
      "GROUP BY StuID, LName, Fname, Sex, PetID, PetType, pet_age, weight\n",
      "HAVING count(PetID) > 1\n",
      "\n",
      "\n",
      "continent.ContId, continent.Continent, count(*) FROM continents, countries GROUP BY continent.ContId, continent.Continent\\n\\n\n",
      "continent.ContId, continent.Continent, count(*) FROM continents, countries GROUP BY continent.ContId, continent.Continent\n",
      "\n",
      "\n",
      "count(*) FROM Has_Pet WHERE StuID > 20 AND PetID > 0\\n\\n', \"count(*) FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID  =  T2.StuID WHERE T1.Sex  =  'F' AND T2.PetID  =  'Dog'\\n\\n\n",
      "count(*) FROM Has_Pet WHERE StuID > 20 AND PetID > 0\n",
      "\n",
      "', \"count(*) FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID  =  T2.StuID WHERE T1.Sex  =  'F' AND T2.PetID  =  'Dog'\n",
      "\n",
      "\n",
      "avg(weight) ,  PetType FROM Has_Pet GROUP BY PetType\\n\\n\n",
      "avg(weight) ,  PetType FROM Has_Pet GROUP BY PetType\n",
      "\n",
      "\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType = 'Cat' AND pet_age > 10)) AND StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType = 'Dog' AND pet_age > 10))\\n\\n\", 'StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\\n\\n\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType = 'Cat' AND pet_age > 10)) AND StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType = 'Dog' AND pet_age > 10))\n",
      "\n",
      "\", 'StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\n",
      "\n",
      "\n",
      "PetType, weight FROM Pets WHERE age = (SELECT min(age) FROM Pets)\\n\\n', 'PetType, weight FROM Has_Pet WHERE StuID = (SELECT StuID FROM Student WHERE Age = (SELECT MIN(Age) FROM Student))\\n\\n\n",
      "PetType, weight FROM Pets WHERE age = (SELECT min(age) FROM Pets)\n",
      "\n",
      "', 'PetType, weight FROM Has_Pet WHERE StuID = (SELECT StuID FROM Student WHERE Age = (SELECT MIN(Age) FROM Student))\n",
      "\n",
      "\n",
      "StuID FROM Student WHERE LName = \"Smith\"\\n\\n', \"StuID FROM Student WHERE LName = 'Smith'\\n\\n\n",
      "StuID FROM Student WHERE LName = \"Smith\"\n",
      "\n",
      "', \"StuID FROM Student WHERE LName = 'Smith'\n",
      "\n",
      "\n",
      "StuID, count(*) FROM Has_Pet GROUP BY StuID\\n\\n\n",
      "StuID, count(*) FROM Has_Pet GROUP BY StuID\n",
      "\n",
      "\n",
      "StuID, weight FROM Has_Pet WHERE PetID > 1\\n\\n\n",
      "StuID, weight FROM Has_Pet WHERE PetID > 1\n",
      "\n",
      "\n",
      "count(*) FROM countries\\n\\n', 'maker.FullName, maker.Id, count(*) FROM car_makers maker LEFT JOIN cars_data cars ON maker.Id = cars.MakeId GROUP BY maker.FullName, maker.Id\\n\\n\n",
      "count(*) FROM countries\n",
      "\n",
      "', 'maker.FullName, maker.Id, count(*) FROM car_makers maker LEFT JOIN cars_data cars ON maker.Id = cars.MakeId GROUP BY maker.FullName, maker.Id\n",
      "\n",
      "\n",
      "StuID, Fname, Sex FROM Student\\nJOIN Has_Pet ON StuID = PetID\\nGROUP BY StuID, Fname, Sex\\nHAVING count(PetID) > 1\\n\\n', 'StuID, LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 3)\\n\\n\n",
      "StuID, Fname, Sex FROM Student\n",
      "JOIN Has_Pet ON StuID = PetID\n",
      "GROUP BY StuID, Fname, Sex\n",
      "HAVING count(PetID) > 1\n",
      "\n",
      "', 'StuID, LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 3)\n",
      "\n",
      "\n",
      "StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\\n\\n', 'StuID FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\\n\\n\n",
      "StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\n",
      "\n",
      "', 'StuID FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\n",
      "\n",
      "\n",
      "count(*) FROM Has_Pet WHERE StuID =  StuID AND PetID =  PetID AND Sex =  'F'\\n\\n\n",
      "count(*) FROM Has_Pet WHERE StuID =  StuID AND PetID =  PetID AND Sex =  'F'\n",
      "\n",
      "\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\\n\\n\n",
      "StuID, Fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 2)\n",
      "\n",
      "\n",
      "StuID FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\\n\\n\n",
      "StuID FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\n",
      "\n",
      "\n",
      "car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_', 'model FROM car_names WHERE horsepower = ( SELECT MIN ( horsepower ) FROM car_names );\\n\\n\n",
      "car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_names.Model, car_names.Make, car_', 'model FROM car_names WHERE horsepower = ( SELECT MIN ( horsepower ) FROM car_names );\n",
      "\n",
      "\n",
      "StuID, LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND LName = \"Smith\" AND Age = 25 AND Sex = \"M\" AND Major = 1 AND Advisor = 1 AND city_code = \"New York\"\\n\\n\n",
      "StuID, LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND LName = \"Smith\" AND Age = 25 AND Sex = \"M\" AND Major = 1 AND Advisor = 1 AND city_code = \"New York\"\n",
      "\n",
      "\n",
      "model FROM car_names WHERE weight < (SELECT avg(weight) FROM cars_data)\\n\\n', 'model FROM car_names WHERE weight < (SELECT avg(weight) FROM cars_data)\\n\\n\n",
      "model FROM car_names WHERE weight < (SELECT avg(weight) FROM cars_data)\n",
      "\n",
      "', 'model FROM car_names WHERE weight < (SELECT avg(weight) FROM cars_data)\n",
      "\n",
      "\n",
      "Maker, Model FROM car_names WHERE Year = 1970\\n\\n\n",
      "Maker, Model FROM car_names WHERE Year = 1970\n",
      "\n",
      "\n",
      "\\n\\tMaker, \\n\\tCOUNT(ModelId) AS ModelCount, \\n\\tCOUNT(Model) AS ModelCount\\nFROM car_makers\\nGROUP BY Maker\\n\\n\n",
      "\n",
      "\tMaker, \n",
      "\tCOUNT(ModelId) AS ModelCount, \n",
      "\tCOUNT(Model) AS ModelCount\n",
      "FROM car_makers\n",
      "GROUP BY Maker\n",
      "\n",
      "\n",
      "0- 3\n",
      "1- 3\n",
      "2- 3\n",
      "3- 3\n",
      "4- 3\n",
      "5- 3\n",
      "6- 3\n",
      "7- 3\n",
      "8- 3\n",
      "9- 3\n"
     ]
    }
   ],
   "source": [
    "#getting the output_seqs from logs:\n",
    "file_name = './logs1/log_50_100-3.txt'\n",
    "output_list = [ [] for i in range(10) ]\n",
    "with open(file_name , 'r') as f:\n",
    "    lines = f.readlines()\n",
    "seen_thread = False\n",
    "for line in lines:\n",
    "    if line.startswith('Thread_num:'):\n",
    "        thread_index = int(line[11])\n",
    "        seen_thread = True\n",
    "    if seen_thread==True and line.startswith('The chosen gen text:  ['):\n",
    "        output_list[thread_index].append(line[24:-2])\n",
    "        print(line[24:-3])\n",
    "        print( line[24:-3].encode().decode('unicode_escape') )\n",
    "        seen_thread==False\n",
    "for index , thread in enumerate(output_list):\n",
    "    print(f'{index}- {len(thread)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "72ed5da6-6dfd-4066-aa72-6edfc5cd3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sequences = []\n",
    "output_sequences.extend(output_list[0])\n",
    "output_sequences.extend(output_list[1])\n",
    "output_sequences.extend(output_list[2])\n",
    "output_sequences.extend(output_list[3])\n",
    "output_sequences.extend(output_list[4])\n",
    "output_sequences.extend(output_list[5])\n",
    "output_sequences.extend(output_list[6])\n",
    "output_sequences.extend(output_list[7])\n",
    "output_sequences.extend(output_list[8])\n",
    "output_sequences.extend(output_list[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "388f1168-585c-4e56-bff1-ab875365b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output_seq/output_sequences_800_end-4.pkl' , 'wb') as f:\n",
    "    pkl.dump(output_sequences , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3720fc99-50c5-4dc0-b2fd-631de9b71431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0- 23\n",
      "1- 23\n",
      "2- 23\n",
      "3- 23\n",
      "4- 23\n",
      "5- 23\n",
      "6- 23\n",
      "7- 23\n",
      "8- 23\n",
      "9- 27\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "with open('output_sequences_test1.pkl', 'rb') as f:  # open a text file\n",
    "    part_of_seq = pkl.load(f)\n",
    "output_list[9].extend(part_of_seq)\n",
    "for index , thread in enumerate(output_list):\n",
    "    print(f'{index}- {len(thread)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e22c2f2-29c5-49e1-9bc0-4e8e0e13750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list[6] = output_list[6][:16]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
