{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604f812d-d489-4c06-8fbd-b251eca43924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yadegari/miniconda3/envs/yadegari_cpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "#Code for sequence-level-voting ensemble using my designed scoring mechanism\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "from collections import defaultdict , Counter\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "NUMBER_of_components = int(5)\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('huggyllama/llama-7b')\n",
    "TOKENIZER.add_special_tokens({'pad_token': '[PAD]'})\n",
    "TOKENIZER.padding_side=\"left\"\n",
    "\n",
    "def group_tokenized_responses( tokenized_responses, inputs_log_prob):\n",
    "        # Dictionary to group indices of identical tokenized responses\n",
    "        groups = defaultdict(list)\n",
    "\n",
    "        # Iterate over the tokenized responses with their indices\n",
    "        for i, tokens in enumerate(tokenized_responses):\n",
    "            # Convert tokens to a tuple (hashable) to use as a dictionary key\n",
    "            token_bag_with_counts = tuple(sorted(Counter(tokens).items()))\n",
    "            groups[token_bag_with_counts].append(i)\n",
    "\n",
    "        # print('groups.keys(): ', groups.keys())\n",
    "        # print('groups: ' , groups)\n",
    "        # Convert the grouped dictionary values into a list of groups\n",
    "        grouped_indices = list(groups.values())\n",
    "\n",
    "        # Calculate the average log probabilities for each group and assign them\n",
    "        for group in grouped_indices:\n",
    "            # Extract log probabilities for the current group\n",
    "            group_probs = [\n",
    "                inputs_log_prob[int(idx % NUMBER_of_components)][ 0, int(idx / NUMBER_of_components)].item()\n",
    "                for idx in group\n",
    "            ]\n",
    "\n",
    "            # Calculate the average probability for the group\n",
    "            avg_prob = np.mean(group_probs)\n",
    "\n",
    "            # Assign the average probability back to each index in the group\n",
    "            for idx in group:\n",
    "                inputs_log_prob[int(idx % NUMBER_of_components)][ 0, int(idx / NUMBER_of_components)] = avg_prob\n",
    "\n",
    "        return grouped_indices, inputs_log_prob\n",
    "\n",
    "    #calculating the similarity score of the two tokenized sentences.\n",
    "def similarity_meassure( hypothesis_tokens , reference_tokens, in_table_keywords):\n",
    "\n",
    "    # hypothesis_tokens = [token for token in hypothesis_tokens if token.upper() not in self.sql_keywords]\n",
    "    # reference_tokens = [token for token in reference_tokens if token.upper() not in self.sql_keywords]\n",
    "\n",
    "    hypothesis_counts = Counter(hypothesis_tokens)\n",
    "    reference_counts = Counter(reference_tokens)\n",
    "    clipped_counts = dict()\n",
    "\n",
    "    for token in hypothesis_tokens:\n",
    "        if token not in reference_counts.keys():\n",
    "            reference_counts[token] = 0\n",
    "        if token in in_table_keywords:\n",
    "            clipped_counts[token] = min(hypothesis_counts[token], reference_counts[token])\n",
    "        else:\n",
    "            clipped_counts[token] = min(hypothesis_counts[token], reference_counts[token])/2\n",
    "    \n",
    "    total_clipped = sum(clipped_counts.values())\n",
    "\n",
    "    similarity = (total_clipped*2+1) / ( len(hypothesis_tokens) + len(reference_tokens) + 1 )\n",
    "    \n",
    "    return math.log(similarity)\n",
    "\n",
    "def ensemble( inputs_ids , inputs_log_prob , starting_batch_input_len, batch_text ):\n",
    "    #function for performing ensemble using the bleu metric between the candidate sequences.\n",
    "    #input:\n",
    "        #inputs_ids: list of torch tensor representing the prompt tokens per component with shape (input_len , num_beam)\n",
    "        #inputs_log_prob: list of torch tensor representing the probability of each input_ids with the shape( 1 , num_beam)\n",
    "        #starting_batch_input_len: list of integers. Indicating the start of the generated text in the input_ids (prompt+genText)\n",
    "        #batch_text: list of string with len()=number_components. Having the prompts for each components.\n",
    "    #return:\n",
    "        #ensembled_inputs_ids: torch tensor with size (batch_size , input_len , num_beam)\n",
    "        #ensembled_inputs_log_prob: torch tensor with size (batch_size , 1 , num_beam)\n",
    "    # print('extra_added_paddings before ensemble: ' , extra_added_paddings)\n",
    "    batch_size = len(inputs_ids)\n",
    "    num_beam = inputs_ids[0].size( dim=-1 )\n",
    "    ensembled_inputs_ids = [  ] #inputs_ids.clone() #?\n",
    "    ensembled_inputs_log_prob = [  ] #inputs_log_prob.clone() #?\n",
    "    \n",
    "    table_creation_part_prompt = batch_text[0].split('Given the following database schema:')[-1].split('Answer the following')[0]\n",
    "    # print('table_creation_part_prompt: ', table_creation_part_prompt)\n",
    "    in_table_keywords = word_tokenize( table_creation_part_prompt )\n",
    "    # print('in_table_keywords: ' , in_table_keywords)\n",
    "    tokenized_responses = []\n",
    "    decoded_text_list = []\n",
    "    #Tokenizing the candidate sequences\n",
    "    for j in range(num_beam):\n",
    "        components_token_list = []\n",
    "        for component in range(0,NUMBER_of_components,1):\n",
    "            # print('component: ' , component)\n",
    "            # print('starting_batch_input_len[component]: ' , starting_batch_input_len[component])\n",
    "            # print( 'inputs_ids[ component ].size(0): ' , inputs_ids[ component ].size(0) )\n",
    "            components_token_list.append( inputs_ids[ component ][:, j ] )\n",
    "        decoded_text_list.extend( TOKENIZER.batch_decode( components_token_list ,\n",
    "                                        skip_special_tokens=True ) )\n",
    "    for text in decoded_text_list: #number of candidates we have for each question\n",
    "        # print(text)\n",
    "        tokenized_responses.append( word_tokenize( text.replace('.' , ' ') ) )\n",
    "    selection_score_list = [] #This scoring is used to select the best candidates. It uses the length penalty to calculate the scores\n",
    "    updating_score_list = [] #This scoring is used to update the score of selected candidates. It does not use the length penalty to calculate the scores\n",
    "\n",
    "    #Finding the identical candidates, take the average of their probability, and only keep one of them with the average probability assigned to it.\n",
    "    grouped_indices, inputs_log_prob = group_tokenized_responses( tokenized_responses, inputs_log_prob)\n",
    "    tmp_input_log_prob = []\n",
    "    for input_id , starting_gen, input_log_prob in zip(inputs_ids,starting_batch_input_len,inputs_log_prob):\n",
    "        gen_text_len = input_id.size(0) - starting_gen\n",
    "        # print(gen_text_len)\n",
    "        tmp_input_log_prob.append( input_log_prob/(gen_text_len**0.1) )\n",
    "    # gen_text_len = self.input_ids_to_gen_text_len(inputs_ids , starting_batch_input_len , extra_added_paddings) #shape(batch_size , 1 , num_candidate_beams)\n",
    "    # tmp_input_log_prob = inputs_log_prob/(gen_text_len**0.1)\n",
    "\n",
    "    #Calculating the similarity score for each candidate\n",
    "    for j in range( len( tokenized_responses ) ): #[tok_component1_beam1, tok_component2_beam1, tok_component3_beam1, ..., tok_component1_beam2, tok_component2_beam2 , ...]\n",
    "        temp_tokenized_responses = tokenized_responses.copy()\n",
    "        tokenized_response = temp_tokenized_responses.pop(j)\n",
    "        selection_score = 0\n",
    "        updating_score = 0\n",
    "        for index , other_response in enumerate(temp_tokenized_responses):\n",
    "            if index>=j:\n",
    "                index+=1\n",
    "            # other_response_prob = torch.exp( inputs_log_prob[ int((index%self.number_of_components)+i) , 0,  int(index/self.number_of_components) ] )\n",
    "            selection_score_with_other_response = tmp_input_log_prob[ index%NUMBER_of_components ][ 0,  int(index/NUMBER_of_components) ] + similarity_meassure( tokenized_response, other_response, in_table_keywords )\n",
    "            updating_score_with_other_response = inputs_log_prob[ index%NUMBER_of_components ][ 0,  int(index/NUMBER_of_components) ] + similarity_meassure( tokenized_response, other_response, in_table_keywords )\n",
    "            # score += self.similarity_meassure( tokenized_response, other_response ) * other_response_prob\n",
    "            # print( 'selection_score_with_other_response: ' , selection_score_with_other_response )\n",
    "            # print('tmp_input_log_prob: ' , tmp_input_log_prob[ index%NUMBER_of_components ][ 0,  int(index/NUMBER_of_components) ])\n",
    "            # print('similarity_meassure: ' , similarity_meassure( tokenized_response, other_response, in_table_keywords ))\n",
    "            # print('selection_score: ' , selection_score)\n",
    "            if selection_score == 0:\n",
    "                selection_score = selection_score_with_other_response\n",
    "                updating_score = updating_score_with_other_response\n",
    "            else:\n",
    "                # print(selection_score_with_other_response.dtype) torch.float32\n",
    "                # print(selection_score.dtype) torch.float32\n",
    "                alpha = max(selection_score_with_other_response , selection_score)\n",
    "                beta = min(selection_score_with_other_response , selection_score)\n",
    "                selection_score = alpha + torch.log1p(torch.exp(beta-alpha))\n",
    "                \n",
    "                alpha = max(updating_score_with_other_response , updating_score)\n",
    "                beta = min(updating_score_with_other_response , updating_score)\n",
    "                updating_score = alpha + torch.log1p(torch.exp(beta-alpha))\n",
    "        # log_score = torch.log( score )#/ len(temp_tokenized_responses) )\n",
    "        selection_log_score = (selection_score + tmp_input_log_prob[ j%NUMBER_of_components] [ 0,  int(j/NUMBER_of_components) ] )#/2\n",
    "        updating_log_score = (updating_score + inputs_log_prob[ j%NUMBER_of_components][ 0,  int(j/NUMBER_of_components) ] )#/2\n",
    "        # print(f'toknes:{tokenized_response} point:{score}')\n",
    "        selection_score_list.append(selection_log_score)\n",
    "        updating_score_list.append(updating_log_score)\n",
    "    \n",
    "\n",
    "    for group in grouped_indices:\n",
    "        is_first_item = True\n",
    "        for index in group:\n",
    "            if is_first_item ==False:\n",
    "                selection_score_list[index] = -100000\n",
    "            else:\n",
    "                is_first_item = False\n",
    "    # print('\\nAfter grouping:\\n')\n",
    "    # for j in range( len( tokenized_responses ) ): \n",
    "    #     print(f'toknes:{tokenized_responses[j]} point:{selection_score_list[j]}')\n",
    "\n",
    "    selected_candidate_list = [] #containing tuples like (component_index , beam_index)\n",
    "    #Finding the sequence with the highest bleu score.\n",
    "    tmp_score_list = selection_score_list.copy()\n",
    "    max_number_of_selections = 5\n",
    "    for beam in range(max_number_of_selections):\n",
    "        max_bleu_score_value = max( tmp_score_list )\n",
    "        max_index_bleu_score = selection_score_list.index(max_bleu_score_value)\n",
    "        tmp_score_list[ max_index_bleu_score ] = -100000\n",
    "        selected_candidate_list.append( ( int(max_index_bleu_score%NUMBER_of_components) , int(max_index_bleu_score/NUMBER_of_components) ) )\n",
    "    # print('selected_candidate_list: ' , selected_candidate_list)\n",
    "    for beam_index in range(len(selected_candidate_list)):\n",
    "        start_of_selected_gen_text = starting_batch_input_len[selected_candidate_list[beam_index][0]]\n",
    "        ensembled_inputs_ids.append( inputs_ids[selected_candidate_list[beam_index][0]][ start_of_selected_gen_text: ,\n",
    "                                                                                                selected_candidate_list[beam_index][1] ] )\n",
    "        # print(f'orig log prob: {inputs_log_prob[selected_candidate_list[beam_index][0]+i, 0, selected_candidate_list[beam_index][1]]}')\n",
    "        # print(f'ensemble prob: {score_list[self.number_of_components * selected_candidate_list[beam_index][1] + selected_candidate_list[beam_index][0]]}')\n",
    "        # ensembled_inputs_log_prob[i+component_index , 0 , beam_index] = ( inputs_log_prob[selected_candidate_list[beam_index][0]+i,\n",
    "        #                                                                 0, selected_candidate_list[beam_index][1]] + score_list[self.number_of_components * selected_candidate_list[beam_index][1] + selected_candidate_list[beam_index][0]] )/2\n",
    "        ensembled_inputs_log_prob.append( updating_score_list[NUMBER_of_components * selected_candidate_list[beam_index][1] + selected_candidate_list[beam_index][0]] )\n",
    "    # print('extra_added_paddings after ensemble: ' , extra_added_paddings)\n",
    "    return ensembled_inputs_ids , ensembled_inputs_log_prob\n",
    "\n",
    "#To use the above algorithm we need the following things: input_ids, inputs_log_prob, starting_batch_input_len, batch_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0757e-a2fc-4ddd-be68-5632d9d9aea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yadegari/miniconda3/envs/yadegari_cpu/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ensembled_inputs_ids:  count(*) FROM singer\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(0.4538, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "1\n",
      "ensembled_inputs_ids:  count(*) FROM singer\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(0.3196, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "2\n",
      "ensembled_inputs_ids:  Name, Country, Age FROM singer ORDER BY Age ASC\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.5062, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "3\n",
      "ensembled_inputs_ids:  Name, Country, Age FROM singer ORDER BY Age DESC\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-2.9997, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "4\n",
      "ensembled_inputs_ids:  avg(Age), min(Age), max(Age) FROM singer WHERE Country = 'France'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.8246, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "5\n",
      "ensembled_inputs_ids:  avg(age) ,  min(age) ,  max(age) FROM singer\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.4633, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "6\n",
      "ensembled_inputs_ids:  t1.name ,  t1.release_year FROM singer AS t1 JOIN MATCH AS t2 ON t1.singer_id  =  t2.youngest_singer ORDER BY t1.release_year LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-15.1967, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "7\n",
      "ensembled_inputs_ids:  DISTINCT T1.name ,  T1.release_year FROM singer AS T1 JOIN singer_in_concert AS T2 ON T1.name  =  T2.Singer_ID WHERE T1.age  <  (SELECT avg(age) FROM singer)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-18.7118, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "8\n",
      "ensembled_inputs_ids:  DISTINCT country FROM singer WHERE Age >  20\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.3518, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "9\n",
      "ensembled_inputs_ids:  Country FROM singer WHERE Age  >  20\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.3017, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "10\n",
      "ensembled_inputs_ids:  country ,  count(*) FROM singer GROUP BY country\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-2.8459, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "11\n",
      "ensembled_inputs_ids:  Country ,  COUNT(*) FROM singer GROUP BY Country\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.0120, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "12\n",
      "ensembled_inputs_ids:  Name FROM singer WHERE Is_male = true AND Age > Average\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.8492, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "13\n",
      "ensembled_inputs_ids:  Song_Name FROM singer WHERE Age > Average\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.9786, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "14\n",
      "ensembled_inputs_ids:  Location, Name FROM stadium WHERE Capacity BETWEEN 5000 AND 10000\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.0230, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "15\n",
      "ensembled_inputs_ids:  location, name FROM station WHERE capacity BETWEEN 5000 AND 10000\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.0519, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "16\n",
      "ensembled_inputs_ids:  max(capacity) ,  avg(capacity) FROM stadium\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.2190, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "17\n",
      "ensembled_inputs_ids:  avg(Capacity) ,  max(Capacity) FROM stadium\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.1584, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "18\n",
      "ensembled_inputs_ids:  Name ,  Capacity FROM stadium GROUP BY Name ORDER BY Average DESC\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.1716, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "19\n",
      "ensembled_inputs_ids:  \tname ,  capacity FROM stadium\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.8995, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "20\n",
      "ensembled_inputs_ids:  count(*) FROM concert WHERE Year  =  \"2014\" OR Year  =  \"2015\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.7275, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "21\n",
      "ensembled_inputs_ids:  count(*) FROM concert WHERE year  =  \"2014\" OR year  =  \"2015\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.7934, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "22\n",
      "ensembled_inputs_ids:  stadium_name ,  count(*) FROM concert GROUP BY stadium_name\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.6795, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "23\n",
      "ensembled_inputs_ids:  count(*) FROM stadium\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.2096, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "24\n",
      "ensembled_inputs_ids:  stadium_name, capacity FROM stadium WHERE year > 2014 GROUP BY stadium_name ORDER BY capacity DESC LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.0659, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "25\n",
      "ensembled_inputs_ids:  T2.name ,  T2.capacity FROM concert AS T1 JOIN stadium AS T2 ON T1.Stadium_ID  =  T2.Stadium_ID GROUP BY T1.Stadium_ID ORDER BY count(*) DESC LIMIT 1;\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-15.0007, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "26\n",
      "ensembled_inputs_ids:  year FROM Concert GROUP BY year ORDER BY count(*) DESC LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-2.7698, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "27\n",
      "ensembled_inputs_ids:  Year FROM concert GROUP BY Year ORDER BY count(*) DESC LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.8010, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "28\n",
      "ensembled_inputs_ids:  name FROM stadium\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-2.6664, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "29\n",
      "ensembled_inputs_ids:  stadium_name FROM stadium WHERE stadium_id NOT IN (SELECT stadium_id FROM concert)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.1498, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "30\n",
      "ensembled_inputs_ids:  Country FROM singer WHERE Age  >  40 INTERSECT SELECT Country FROM singer WHERE Age  <  30\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.5031, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "31\n",
      "ensembled_inputs_ids:  Name FROM stadium EXCEPT SELECT T1.name FROM stadium AS T1 JOIN concert AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T2.year  =  2014\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.3111, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "32\n",
      "ensembled_inputs_ids:  name FROM stadium EXCEPT SELECT T2.name FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T1.year  =  2014\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-9.2380, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "33\n",
      "ensembled_inputs_ids:  concert_Name ,  count(*) FROM concert GROUP BY concert_Name\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.6898, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "34\n",
      "ensembled_inputs_ids:  * FROM concert\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.9672, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "35\n",
      "ensembled_inputs_ids:  Singer_Name ,  count(*) FROM singer GROUP BY Singer_Name\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.7821, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "36\n",
      "ensembled_inputs_ids:  S.Name ,  count(*) FROM singer AS S GROUP BY S.Name\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-12.0045, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "37\n",
      "ensembled_inputs_ids:  Name FROM singer WHERE Year = 2014\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.2937, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "38\n",
      "ensembled_inputs_ids:  Singer_Name FROM singer WHERE Year  =  2014\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.7341, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "39\n",
      "ensembled_inputs_ids:  T1.name , T1.nation FROM singers AS T1 JOIN songs AS T2 ON T1.song_name  =  T2.song_name WHERE T2.song_name  =  'Hey'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-16.9398, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "40\n",
      "ensembled_inputs_ids:  T1.Name, T1.Country FROM Singer AS T1 JOIN Concert AS T2 ON T1.Singer_ID  =  T2.Singer_ID WHERE T2.Theme  =  \"Hey\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-16.0993, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "41\n",
      "ensembled_inputs_ids:  Name, Location FROM stadium WHERE Year IN (2014, 2015)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-9.1694, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "42\n",
      "ensembled_inputs_ids:  name, location FROM stadium WHERE YEAR IN (2014, 2015)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.0102, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "43\n",
      "ensembled_inputs_ids:  count(*) FROM concert\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.9090, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "44\n",
      "ensembled_inputs_ids:  COUNT(*) FROM concert WHERE Stadium_ID = 1;\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-9.0248, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "45\n",
      "ensembled_inputs_ids:  count(*) FROM Pets WHERE weight > 10\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.4355, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "46\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet WHERE weight  >  10\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.9540, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "47\n",
      "ensembled_inputs_ids:  PetType ,  weight FROM Pets WHERE age  =  (SELECT min(age) FROM Pets)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.7303, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "48\n",
      "ensembled_inputs_ids:  weight FROM Pets WHERE PetType = 'dog' AND age = (SELECT min(age) FROM Pets WHERE PetType = 'dog')\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-15.1314, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "49\n",
      "ensembled_inputs_ids:  max(weight) ,  pet_type FROM Has_Pet GROUP BY pet_type\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.4385, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "50\n",
      "ensembled_inputs_ids:  PetType ,  max(weight) FROM Pets GROUP BY PetType\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.7893, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "51\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet WHERE StuID >  20\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.8391, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "52\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet WHERE StuID > 20 AND PetID > 0\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.6881, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "53\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet WHERE StuID IN ( SELECT StuID FROM Student WHERE Sex  =  \"F\" )\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-12.6036, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "54\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet AS T1 JOIN Student AS T2 ON T1.StuID  =  T2.StuID WHERE T2.sex  =  \"F\" AND T1.PetType  =  \"Dog\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.1767, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "55\n",
      "ensembled_inputs_ids:  count(DISTINCT PetType) FROM Has_Pet\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-1.5323, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "56\n",
      "ensembled_inputs_ids:  count(DISTINCT PetType) FROM Has_Pet\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-1.8077, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "57\n",
      "ensembled_inputs_ids:  fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType =  \"Cat\" OR PetType =  \"Dog\"))\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.1590, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "58\n",
      "ensembled_inputs_ids:  LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.7643, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "59\n",
      "ensembled_inputs_ids:  t1.Fname FROM Student AS t1 JOIN Has_Pet AS t2 ON t1.StuID  =  t2.StuID WHERE PetType  =  'Cat' INTERSECT SELECT t1.Fname FROM Student AS t1 JOIN Has_Pet AS t2 ON t1.StuID  =  t2.StuID WHERE PetType  =  'Dog'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.4756, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "60\n",
      "ensembled_inputs_ids:  fname FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType  =  \"Cat\" INTERSECT SELECT PetID FROM Pets WHERE PetType  =  \"Dog\"))\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-14.3935, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "61\n",
      "ensembled_inputs_ids:  StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-9.4536, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "62\n",
      "ensembled_inputs_ids:  StuID, Major, Age FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet WHERE PetID = 0)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.5678, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "63\n",
      "ensembled_inputs_ids:  StuID FROM Has_Pet WHERE PetID IS NULL\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.6138, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "64\n",
      "ensembled_inputs_ids:  StuID FROM Student WHERE PetID IS NULL\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.7931, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "65\n",
      "ensembled_inputs_ids:  fname ,  age FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID IN (SELECT PetID FROM Pets WHERE PetType  =  \"Dog\"))\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-16.0897, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "66\n",
      "ensembled_inputs_ids:  StuName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 1) AND StuName NOT IN (SELECT StuName FROM Has_Pet WHERE PetID = 2)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-17.6588, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "67\n",
      "ensembled_inputs_ids:  PetType, weight FROM Pets WHERE age = (SELECT min(age) FROM Pets)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-7.5470, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "68\n",
      "ensembled_inputs_ids:  PetType, weight FROM Has_Pet WHERE StuID = (SELECT min(StuID) FROM Has_Pet)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.4345, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "69\n",
      "ensembled_inputs_ids:  StuID, weight FROM Has_Pet WHERE pet_age > 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.7119, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "70\n",
      "ensembled_inputs_ids:  StuID, weight FROM Has_Pet WHERE age  >  1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.7201, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "71\n",
      "ensembled_inputs_ids:  avg(pet_age) ,  max(pet_age) FROM Has_Pet\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.9355, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "72\n",
      "ensembled_inputs_ids:  avg(pet_age) ,  max(pet_age) FROM Pets GROUP BY pet_type\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.9789, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "73\n",
      "ensembled_inputs_ids:  avg(weight) FROM Has_Pet\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.4528, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "74\n",
      "ensembled_inputs_ids:  avg(weight) ,  PetType FROM Has_Pet GROUP BY PetType\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.1783, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "75\n",
      "ensembled_inputs_ids:  DISTINCT T1.Fname, T1.Age FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID  =  T2.StuID\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.2930, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "76\n",
      "ensembled_inputs_ids:  DISTINCT T1.Fname, T1.Age FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID = T2.StuID\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-9.7803, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "77\n",
      "ensembled_inputs_ids:  StuID FROM Student WHERE LName = \"Smith\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.1791, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "78\n",
      "ensembled_inputs_ids:  StuID FROM Student WHERE LName = 'Smith'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.5977, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "79\n",
      "ensembled_inputs_ids:  count(*) FROM Has_Pet GROUP BY StuID\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.5710, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "80\n",
      "ensembled_inputs_ids:  StuID ,  count(*) FROM Has_Pet GROUP BY StuID\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.0690, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "81\n",
      "ensembled_inputs_ids:  DISTINCT T1.Fname ,  T1.LName FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID  =  T2.StuID WHERE T1.sex  =  \"F\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.9180, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "82\n",
      "ensembled_inputs_ids:  DISTINCT T1.Fname ,  T1.LName FROM Student AS T1 JOIN Has_Pet AS T2 ON T1.StuID  =  T2.StuID GROUP BY T2.PetID HAVING count(*)  >  1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-12.5229, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "83\n",
      "ensembled_inputs_ids:  StuID, LName FROM Student WHERE StuID IN (SELECT StuID FROM Has_Pet WHERE PetID = 3)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-14.0254, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "84\n",
      "ensembled_inputs_ids:  LName FROM Student WHERE StuID = (SELECT StuID FROM Has_Pet WHERE PetID = (SELECT PetID FROM Pets WHERE PetType = \"Cat\" AND pet_age = 3));\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.3980, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "85\n",
      "ensembled_inputs_ids:  avg(pet_age) FROM Student WHERE StuID NOT IN (SELECT StuID FROM Has_Pet)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.2672, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "86\n",
      "ensembled_inputs_ids:  avg(age) FROM Student WHERE StuID NOT IN ( SELECT StuID FROM Has_Pet )\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.7505, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "87\n",
      "ensembled_inputs_ids:  count(*) FROM continents\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(0.7917, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "88\n",
      "ensembled_inputs_ids:  count(*) FROM continents\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(0.5075, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "89\n",
      "ensembled_inputs_ids:  continent ,  count(*) FROM continents GROUP BY continent\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.3411, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "90\n",
      "ensembled_inputs_ids:  ContId, Continent, Countries FROM continents\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.3196, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "91\n",
      "ensembled_inputs_ids:  count(*) FROM countries\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-0.3150, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "92\n",
      "ensembled_inputs_ids:  count(*) FROM countries\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(0.1423, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "93\n",
      "ensembled_inputs_ids:  Maker ,  COUNT(*) FROM car_names GROUP BY Maker\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.3603, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "94\n",
      "ensembled_inputs_ids:  full_name ,  id ,  model_count FROM car_makers\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.0173, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "95\n",
      "ensembled_inputs_ids:  MIN(horsepower) ,  model_id FROM cars_data GROUP BY model_id\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.8266, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "96\n",
      "ensembled_inputs_ids:  model FROM cars_data WHERE horsepower  =  ( SELECT MIN ( horsepower ) FROM cars_data );\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.7895, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "97\n",
      "ensembled_inputs_ids:  model FROM cars_data WHERE weight  <  (SELECT avg(weight) FROM cars_data)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.6698, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "98\n",
      "ensembled_inputs_ids:  model FROM car_names WHERE weight  <  (SELECT avg(weight) FROM car_names)\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.4889, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "99\n",
      "ensembled_inputs_ids:  maker FROM cars_data WHERE year = 1970\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.3738, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "100\n",
      "ensembled_inputs_ids:  DISTINCT T1.make FROM car_names AS T1 JOIN cars_data AS T2 ON T1.make = T2.make WHERE T2.year = 1970;\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-14.2785, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "101\n",
      "ensembled_inputs_ids:  Make, Year FROM cars_data WHERE Year = 1960\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.2738, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "102\n",
      "ensembled_inputs_ids:  Maker, Year FROM cars_data WHERE Year = 1900\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.9414, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "103\n",
      "ensembled_inputs_ids:  DISTINCT Model FROM cars_data WHERE Year > 1980\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.0076, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "104\n",
      "ensembled_inputs_ids:  DISTINCT T1.Model FROM car_names AS T1 JOIN cars_data AS T2 ON T1.Make = T2.Make WHERE T2.Year > 1980\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-13.2574, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "105\n",
      "ensembled_inputs_ids:  continent ,  count(*) FROM car_makers GROUP BY continent\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-5.4060, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "106\n",
      "ensembled_inputs_ids:  continent ,  count(*) FROM continents GROUP BY continent\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.2597, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "107\n",
      "ensembled_inputs_ids:  CountryName FROM car_makers GROUP BY CountryName ORDER BY COUNT(*) DESC LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.0544, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "108\n",
      "ensembled_inputs_ids:  CountryName FROM car_makers GROUP BY CountryName ORDER BY count(*) DESC LIMIT 1\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.8006, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "109\n",
      "ensembled_inputs_ids:  Maker ,  COUNT(*) FROM car_names GROUP BY Maker\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.7670, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "110\n",
      "ensembled_inputs_ids:  Maker ,  COUNT(*) FROM car_makers GROUP BY Maker\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-10.1989, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "111\n",
      "ensembled_inputs_ids:  Accelerate FROM cars_data WHERE MakeId =  \"amc hornet sportabout (sw)\"\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-8.3932, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "112\n",
      "ensembled_inputs_ids:  Accelerate FROM cars_data WHERE Make = \"amc\" AND Model = \"hornet sportabout (sw)\";\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.7301, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "113\n",
      "ensembled_inputs_ids:  count(*) FROM car_makers WHERE country = 'France'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-2.8705, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "114\n",
      "ensembled_inputs_ids:  count(*) FROM car_makers WHERE country  =  'France'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.8481, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "115\n",
      "ensembled_inputs_ids:  count(*) FROM car_names WHERE country = 'USA'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.0463, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "116\n",
      "ensembled_inputs_ids:  count(*) FROM car_names WHERE Make =  'United States'\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-11.8607, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "117\n",
      "ensembled_inputs_ids:  avg(mpg) FROM cars_data WHERE cylinders = 4;\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.3496, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "118\n",
      "ensembled_inputs_ids:  avg(mpg) FROM cars_data WHERE cylinders = 4\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-3.2206, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "119\n",
      "ensembled_inputs_ids:  min(weight) FROM cars_data WHERE cylinders = 8 AND year = 1974\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.9287, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "120\n",
      "ensembled_inputs_ids:  min(Weight) FROM cars_data WHERE Year = 1974 AND Cylinders = 8\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-6.4462, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "121\n",
      "ensembled_inputs_ids:  Maker, Model FROM car_makers\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.7491, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "122\n",
      "ensembled_inputs_ids:  Maker, Model FROM car_names\n",
      "\n",
      "\n",
      "ensembled_inputs_log_prob:  tensor(-4.2931, device='cuda:0')\n",
      "----------------------------------------------------------\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "prefix = './MBRoutput_sequences_total-4'\n",
    "post_fixes = ['_batch_text' , '_input_ids' , '_inputs_log_prob' , '_starting_batch_input_len' ]\n",
    "lists_of_parameter_list = [ [],[],[],[] ]\n",
    "#reading the output files to get the parameter to perform ensemble.\n",
    "for index, post_fix in enumerate(post_fixes):\n",
    "    filename = prefix + post_fix + '.pkl'\n",
    "    with open(filename , 'rb') as f:\n",
    "        lists_of_parameter_list[index] = pkl.load(f)\n",
    "final_answers = [[], [], [], [], []]\n",
    "counter = 0\n",
    "for batch_text, inputs_ids, inputs_log_prob, starting_batch_input_len in zip(lists_of_parameter_list[0], lists_of_parameter_list[1], lists_of_parameter_list[2], lists_of_parameter_list[3]):\n",
    "    print(counter)\n",
    "    counter += 1\n",
    "    ensembled_inputs_ids , ensembled_inputs_log_prob = ensemble(inputs_ids, inputs_log_prob, starting_batch_input_len, batch_text )\n",
    "    ensembled_inputs_text = TOKENIZER.batch_decode( ensembled_inputs_ids ,\n",
    "                                        skip_special_tokens=True )\n",
    "    for i, answer_list in enumerate(final_answers):\n",
    "        answer_list.append(ensembled_inputs_text[i])\n",
    "    # final_answers.append(ensembled_inputs_text[0])\n",
    "    print('ensembled_inputs_ids: ' , ensembled_inputs_text[0])\n",
    "    print('ensembled_inputs_log_prob: ' , ensembled_inputs_log_prob[0])\n",
    "    print('----------------------------------------------------------')\n",
    "\n",
    "final_output_filenames = [ './MBRoutput_sequences_total-4_rank1.pkl', './MBRoutput_sequences_total-4_rank2.pkl', './MBRoutput_sequences_total-4_rank3.pkl',\n",
    "                         './MBRoutput_sequences_total-4_rank4.pkl', './MBRoutput_sequences_total-4_rank5.pkl']\n",
    "for i, file_name in enumerate(final_output_filenames):\n",
    "    with open(file_name , 'wb')as f:\n",
    "        pkl.dump(final_answers[i] , f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b1e6b9-4861-4e27-b1cf-65f5619176c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "1034\n",
      "211\n",
      "1034\n",
      "211\n",
      "1034\n",
      "211\n",
      "1034\n",
      "211\n",
      "1034\n"
     ]
    }
   ],
   "source": [
    "prefixes = ['./outputs2_0_3/output_sequences_' , './outputs2_6_9/output_sequences_', './outputs4_12_15/output_sequences_',\n",
    "           './outputs4_3_6/output_sequences_' , './outputs4_9_12/output_sequences_']\n",
    "post_fixes = ['_batch_text' , '_input_ids' , '_inputs_log_prob' , '_starting_batch_input_len' ]\n",
    "#What do we need for the ensemble?\n",
    "#for every item, lets have a list of lists.\n",
    "for post_fix in post_fixes:\n",
    "    components_list_of_outputs = [ [], [], [], [], [] ]\n",
    "    for index , prefix in enumerate(prefixes):\n",
    "        filename = prefix + 'total-4' + post_fix + '.pkl'\n",
    "        with open(filename , 'rb') as f:\n",
    "            list_of_outputs = pkl.load(f)\n",
    "        if post_fix== '_starting_batch_input_len':\n",
    "            print(len(list_of_outputs))\n",
    "            new_list_of_outputs = [ele for ele in list_of_outputs[:200] for i in range( 5 )]\n",
    "            new_list_of_outputs.extend([ele for ele in list_of_outputs[200:-2] for i in range( 3 )])\n",
    "            new_list_of_outputs.extend([list_of_outputs[-2] for i in range( 5 )])\n",
    "            new_list_of_outputs.extend([list_of_outputs[-1] for i in range( 2 )])\n",
    "            list_of_outputs = new_list_of_outputs\n",
    "            print(len(list_of_outputs))\n",
    "        components_list_of_outputs[index] = list_of_outputs\n",
    "    postfix_total_list = []\n",
    "    for a, b, c, d, e in zip (components_list_of_outputs[0], components_list_of_outputs[1], components_list_of_outputs[2], components_list_of_outputs[3], components_list_of_outputs[4]):\n",
    "        postfix_total_list.append([a,b,c,d,e])\n",
    "    new_prefix = './MBRoutput_sequences_total-4'\n",
    "    output_filename = new_prefix + post_fix + '.pkl'\n",
    "    with open(output_filename , 'wb')as f:\n",
    "        pkl.dump(postfix_total_list , f)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b8d4b7-b2b3-4091-b449-8f7500d86c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yadegari/miniconda3/envs/yadegari_cpu/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "#grouping the pieces of output_sequences\n",
    "import pickle as pkl\n",
    "prefix = './outputs2_0_3/output_sequences_'\n",
    "post_fixes = ['_batch_text' , '_input_ids' , '_inputs_log_prob' , '_starting_batch_input_len' ]\n",
    "# post_fixes = ['_input_ids' , '_inputs_log_prob']\n",
    "for post_fix in post_fixes:\n",
    "    output_sequences = []\n",
    "    for i in range(0 , 1050 , 50):\n",
    "        if i <1000:\n",
    "            if i == 0: \n",
    "                file_name = prefix + '0_'  + str(i+50).lstrip('0') + '-4' + post_fix + '.pkl'\n",
    "            else:\n",
    "                file_name = prefix + str(i).lstrip('0') + '_' + str(i+50).lstrip('0') + '-4' + post_fix + '.pkl'\n",
    "        else:\n",
    "            file_name = prefix + str(i).lstrip('0') + '_end' + '-4' + post_fix + '.pkl'\n",
    "        # print(file_name)\n",
    "        with open(file_name , 'rb') as f:\n",
    "            part_of_output = pkl.load(f)\n",
    "        output_sequences.extend(part_of_output)\n",
    "    with open(prefix + 'total-4' + post_fix + '.pkl' , 'wb')as h:\n",
    "        pkl.dump(output_sequences , h)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
